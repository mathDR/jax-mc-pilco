{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e9abc4",
   "metadata": {},
   "source": [
    "# Testing the PILCO framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ~/dev/marthaler/header.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472b1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel.marthaler/.pyenv/versions/3.11.1/envs/pilco/lib/python3.11/site-packages/cola/backends/backends.py:75: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(cls, tree_flatten, tree_unflatten)\n"
     ]
    }
   ],
   "source": [
    "# Enable Float64 for more stable matrix inversions.\n",
    "import jax\n",
    "from jax import Array, config\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax.random as jr\n",
    "from jaxtyping import ArrayLike, install_import_hook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import gpjax as gpx\n",
    "\n",
    "\n",
    "key = jr.key(123)\n",
    "\n",
    "cols = mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a634df7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2b800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample from a single mean and covariance\n",
    "def sample_mvnormal(key, mean, cov, num_samples):\n",
    "    return jr.multivariate_normal(key, mean, cov, (num_samples,))\n",
    "\n",
    "# Vectorize the sampling function\n",
    "vectorized_sample = jax.vmap(sample_mvnormal, in_axes=(None, 0, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b20d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_pole_cost(\n",
    "    states_sequence: ArrayLike, \n",
    "    target_state: ArrayLike = jnp.array([jnp.pi,0.0]), \n",
    "    lengthscales: ArrayLike = jnp.array([3.0,1.0]),\n",
    "    angle_index:int = 2,\n",
    "    pos_index:int = 0\n",
    ")->Array:\n",
    "    \"\"\"\n",
    "    Cost function given by the combination of the saturated distance between |theta| and 'target angle', and between x and 'target position'.\n",
    "    \"\"\"\n",
    "    x = states_sequence[pos_index]\n",
    "    theta = states_sequence[angle_index]\n",
    "\n",
    "    target_x = target_state[1]\n",
    "    target_theta = target_state[0]\n",
    "\n",
    "    return 1 - jnp.exp(\n",
    "        -(jnp.square((jnp.abs(theta) - target_theta) / lengthscales[0])) - jnp.square((x - target_x) / lengthscales[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4810d6",
   "metadata": {},
   "source": [
    "## Generate the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b1bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"InvertedPendulum-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de289fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dim = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6fb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_exploration, _ = env.reset()\n",
    "state_dim = initial_state_exploration.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f020d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random controller\n",
    "from controllers import RandomController\n",
    "policy = RandomController(state_dim,action_dim,True,3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d6451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_timesteps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60662edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "ep_return_full = 0\n",
    "ep_return_sampled = 0\n",
    "key = jr.key(42)\n",
    "x = initial_state_exploration.copy()\n",
    "for timestep in range(explore_timesteps):\n",
    "    key, subkey = jr.split(key)\n",
    "    u = policy.compute_action(x,timestep,subkey)\n",
    "    #print(u)\n",
    "    z = env.step(np.array(u))\n",
    "    #print(z)\n",
    "    #x_new, r, done, _, __ = env.step(np.array(u))\n",
    "    x_new = z[0]\n",
    "    r = z[1]\n",
    "    X.append(jnp.hstack((x, u)))\n",
    "    Y.append(x_new - x)\n",
    "    ep_return_sampled += r\n",
    "    x = x_new\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "802a5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = gpx.Dataset(X=X, y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf7b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_learning.mgpr import DynamicalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44177063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicalModel(data=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce380ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0577e863ad7485f9213e5b8f8def5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel.marthaler/.pyenv/versions/3.11.1/envs/pilco/lib/python3.11/site-packages/cola/backends/backends.py:75: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(cls, tree_flatten, tree_unflatten)\n",
      "/Users/daniel.marthaler/.pyenv/versions/3.11.1/envs/pilco/lib/python3.11/site-packages/cola/backends/backends.py:75: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(cls, tree_flatten, tree_unflatten)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4699d1435e144e2fa7faac1f7576cc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21f9b8e759940aab13321f899a4ef70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec92aa6cbab453b87ac930689f393b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4695266b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel.marthaler/.pyenv/versions/3.11.1/envs/pilco/lib/python3.11/site-packages/cola/backends/backends.py:75: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(cls, tree_flatten, tree_unflatten)\n"
     ]
    }
   ],
   "source": [
    "# Now do a rollout with this model\n",
    "\n",
    "# Generate an initial state\n",
    "x0, _ = env.reset()\n",
    "key, subkey = jr.split(key)\n",
    "# Generate an initial action\n",
    "u0 = policy.compute_action(x,timestep,subkey)\n",
    "initial_state = jnp.hstack((x, u)).reshape(1,-1)\n",
    "# Compute the moments from the trained GP transition function\n",
    "predictive_moments = model.predict_all_outputs(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c303f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some particles\n",
    "num_particles = 100\n",
    "init_samples = jnp.squeeze(\n",
    "    vectorized_sample(\n",
    "        key, predictive_moments[:,:,0], jax.vmap(jnp.diag)(predictive_moments[:,:,1]), num_particles\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd085e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpjax.parameters import (\n",
    "    Parameter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04782b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "controllers.RandomController"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfbdca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969483ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphdef, params, *static_state = nnx.split(policy, Parameter, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b93bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from flax import nnx\n",
    "Model = tp.TypeVar(\"Model\", bound=nnx.Module)\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    KeyArray,\n",
    "    ScalarFloat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8cfc306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scan(f, init, xs, length=None):\n",
    "#   if xs is None:\n",
    "#     xs = [None] * length\n",
    "#   carry = init\n",
    "#   ys = []\n",
    "#   for x in xs:\n",
    "#     carry, y = f(carry, x)\n",
    "#     ys.append(y)\n",
    "#   return carry, np.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5771803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_all(\n",
    "    policy,#: Controller,\n",
    "    samples: ArrayLike,\n",
    "    model: Model,\n",
    "    timesteps: ArrayLike,\n",
    "    key: KeyArray = jr.PRNGKey(42),\n",
    "    time_horizon: int=50,\n",
    "    num_particles:int=100\n",
    ")->ScalarFloat:\n",
    "    # Should wrap this in scan so we can jit compile it?\n",
    "    costs = []\n",
    "    for t in range(timestep+1,timestep+time_horizon):\n",
    "        # Now generate some actions to take for these states\n",
    "        key, *subkeys = jr.split(key,num_particles+1)\n",
    "        u = jax.vmap(policy.compute_action)(samples,jnp.tile(t,num_particles),jnp.array(subkeys))\n",
    "        this_state = jnp.hstack((samples, u))\n",
    "        # should compute rewards here?\n",
    "        predictive_moments = model.predict_all_outputs(this_state)\n",
    "        # Generate samples\n",
    "        key, subkey = jr.split(key)\n",
    "        samples = jnp.squeeze(\n",
    "            vectorized_sample(\n",
    "                key, predictive_moments[:,:,0], jax.vmap(jnp.diag)(predictive_moments[:,:,1]), 1\n",
    "            )\n",
    "        )\n",
    "        costs.append(jnp.sum(jax.vmap(cart_pole_cost)(samples)))\n",
    "    return jnp.mean(jnp.array(costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2e0ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(52.282467, dtype=float64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout_all(policy,init_samples,model,timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b22b5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85fc53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles=100\n",
    "def one_rollout_step(carry, t):\n",
    "    compute_action, predict_all_outputs, key, samples, total_cost = carry\n",
    "    key, *subkeys = jr.split(key,num_particles+1)\n",
    "    u = jax.vmap(compute_action)(samples,jnp.tile(t,num_particles),jnp.array(subkeys))\n",
    "    this_state = jnp.hstack((samples, u))\n",
    "    predictive_moments = predict_all_outputs(this_state)\n",
    "    key, subkey = jr.split(key)\n",
    "    samples = jnp.squeeze(\n",
    "        vectorized_sample(\n",
    "            key, predictive_moments[:,:,0], jax.vmap(jnp.diag)(predictive_moments[:,:,1]), 1\n",
    "        )\n",
    "    )\n",
    "    cost = jnp.sum(jax.vmap(cart_pole_cost)(samples))\n",
    "    return (compute_action,predict_all_outputs,key,samples,total_cost+cost), cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "545aa652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(\n",
    "    policy,#: Controller,\n",
    "    model,#Model\n",
    "    init_samples: ArrayLike,\n",
    "    timesteps: ArrayLike,\n",
    "    key: KeyArray = jr.PRNGKey(42),\n",
    ")->ScalarFloat:\n",
    "    action = Partial(policy.compute_action)\n",
    "    pao = Partial(model.predict_all_outputs)\n",
    "    (action,pao,key,samples,total_cost), result = jax.lax.scan(\n",
    "        one_rollout_step, (action,pao,key,init_samples,0), timesteps\n",
    "    )\n",
    "    return total_cost/len(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2dd1aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 50\n",
    "timesteps = jnp.arange(timestep+1,timestep+time_horizon)\n",
    "cost = rollout(policy,model,init_samples,timesteps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3746cd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(52.282467, dtype=float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c3b8e",
   "metadata": {},
   "source": [
    "should partial map the above loop so that a given set of controller parameters are passed in.\n",
    "This would change the \"Compute action\" function so that we need the parameters at each call.  So maybe the controller won't be a class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(  # noqa: PLR0913\n",
    "    *,\n",
    "    model: Model,\n",
    "    objective: Objective,\n",
    "    train_data: Dataset,\n",
    "    optim: ox.GradientTransformation,\n",
    "    params_bijection: tp.Union[dict[Parameter, Bijector], None] = DEFAULT_BIJECTION,\n",
    "    key: KeyArray = jr.PRNGKey(42),\n",
    "    num_iters: int = 100,\n",
    "    batch_size: int = -1,\n",
    "    log_rate: int = 10,\n",
    "    verbose: bool = True,\n",
    "    unroll: int = 1,\n",
    "    safe: bool = True,\n",
    ") -> tuple[Model, jax.Array]:\n",
    "    r\"\"\"Train a Module model with respect to a supplied objective function.\n",
    "    Optimisers used here should originate from Optax.\n",
    "\n",
    "    Example:\n",
    "    ```pycon\n",
    "        >>> import jax.numpy as jnp\n",
    "        >>> import jax.random as jr\n",
    "        >>> import optax as ox\n",
    "        >>> import gpjax as gpx\n",
    "        >>> from gpjax.parameters import PositiveReal, Static\n",
    "        >>>\n",
    "        >>> # (1) Create a dataset:\n",
    "        >>> X = jnp.linspace(0.0, 10.0, 100)[:, None]\n",
    "        >>> y = 2.0 * X + 1.0 + 10 * jr.normal(jr.PRNGKey(0), X.shape)\n",
    "        >>> D = gpx.Dataset(X, y)\n",
    "        >>> # (2) Define your model:\n",
    "        >>> class LinearModel(nnx.Module):\n",
    "        >>>     def __init__(self, weight: float, bias: float):\n",
    "        >>>         self.weight = PositiveReal(weight)\n",
    "        >>>         self.bias = Static(bias)\n",
    "        >>>\n",
    "        >>>     def __call__(self, x):\n",
    "        >>>         return self.weight.value * x + self.bias.value\n",
    "        >>>\n",
    "        >>> model = LinearModel(weight=1.0, bias=1.0)\n",
    "        >>>\n",
    "        >>> # (3) Define your loss function:\n",
    "        >>> def mse(model, data):\n",
    "        >>>     pred = model(data.X)\n",
    "        >>>     return jnp.mean((pred - data.y) ** 2)\n",
    "        >>>\n",
    "        >>> # (4) Train!\n",
    "        >>> trained_model, history = gpx.fit(\n",
    "        >>>     model=model, objective=mse, train_data=D, optim=ox.sgd(0.001), num_iters=1000\n",
    "        >>> )\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        model (Model): The model Module to be optimised.\n",
    "        objective (Objective): The objective function that we are optimising with\n",
    "            respect to.\n",
    "        train_data (Dataset): The training data to be used for the optimisation.\n",
    "        optim (GradientTransformation): The Optax optimiser that is to be used for\n",
    "            learning a parameter set.\n",
    "        num_iters (int): The number of optimisation steps to run. Defaults\n",
    "            to 100.\n",
    "        batch_size (int): The size of the mini-batch to use. Defaults to -1\n",
    "            (i.e. full batch).\n",
    "        key (KeyArray): The random key to use for the optimisation batch\n",
    "            selection. Defaults to jr.PRNGKey(42).\n",
    "        log_rate (int): How frequently the objective function's value should\n",
    "            be printed. Defaults to 10.\n",
    "        verbose (bool): Whether to print the training loading bar. Defaults\n",
    "            to True.\n",
    "        unroll (int): The number of unrolled steps to use for the optimisation.\n",
    "            Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        A tuple comprising the optimised model and training history.\n",
    "    \"\"\"\n",
    "    if safe:\n",
    "        # Check inputs.\n",
    "        _check_model(model)\n",
    "        _check_train_data(train_data)\n",
    "        _check_optim(optim)\n",
    "        _check_num_iters(num_iters)\n",
    "        _check_batch_size(batch_size)\n",
    "        _check_log_rate(log_rate)\n",
    "        _check_verbose(verbose)\n",
    "\n",
    "    # Model state filtering\n",
    "\n",
    "    graphdef, params, *static_state = nnx.split(model, Parameter, ...)\n",
    "\n",
    "    # Parameters bijection to unconstrained space\n",
    "    if params_bijection is not None:\n",
    "        params = transform(params, params_bijection, inverse=True)\n",
    "\n",
    "    # Loss definition\n",
    "    def loss(params: nnx.State, batch: Dataset) -> ScalarFloat:\n",
    "        params = transform(params, params_bijection)\n",
    "        model = nnx.merge(graphdef, params, *static_state)\n",
    "        return objective(model, batch)\n",
    "\n",
    "    # Initialise optimiser state.\n",
    "    opt_state = optim.init(params)\n",
    "\n",
    "    # Mini-batch random keys to scan over.\n",
    "    iter_keys = jr.split(key, num_iters)\n",
    "\n",
    "    # Optimisation step.\n",
    "    def step(carry, key):\n",
    "        params, opt_state = carry\n",
    "\n",
    "        if batch_size != -1:\n",
    "            batch = get_batch(train_data, batch_size, key)\n",
    "        else:\n",
    "            batch = train_data\n",
    "\n",
    "        loss_val, loss_gradient = jax.value_and_grad(loss)(params, batch)\n",
    "        updates, opt_state = optim.update(loss_gradient, opt_state, params)\n",
    "        params = ox.apply_updates(params, updates)\n",
    "\n",
    "        carry = params, opt_state\n",
    "        return carry, loss_val\n",
    "\n",
    "    # Optimisation scan.\n",
    "    scan = vscan if verbose else jax.lax.scan\n",
    "\n",
    "    # Optimisation loop.\n",
    "    (params, _), history = scan(step, (params, opt_state), (iter_keys), unroll=unroll)\n",
    "\n",
    "    # Parameters bijection to constrained space\n",
    "    if params_bijection is not None:\n",
    "        params = transform(params, params_bijection)\n",
    "\n",
    "    # Reconstruct model\n",
    "    model = nnx.merge(graphdef, params, *static_state)\n",
    "\n",
    "    return model, history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
